{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d6d475f9",
   "metadata": {},
   "source": [
    "# Working with xml / html\n",
    "\n",
    "You may be familiar with markup languages. They allow us to add tags to a document that contain information about how the document is to be displayed, formatted, or processed. \n",
    "\n",
    "HTML - HyperText Markup Language - is the standard markup language for webpages. The html for a basic webpage may look something like this:\n",
    "\n",
    "```\n",
    "<!DOCTYPE HTML>\n",
    "<html>\n",
    "\t<head>\n",
    "\t\t<title>[Website Title]</title>\n",
    "        <link rel=\"stylesheet\" href=\"link/to/stylesheet.css\" />\n",
    "    </head>\n",
    "    <body>\n",
    "        <div type = \"section\">\n",
    "            <h1>[Website Title]</h1>\n",
    "            <p>[A paragraph of content.........]</p>\n",
    "        </div>\n",
    "    </body>\n",
    "</html>\n",
    "```\n",
    "\n",
    "In the example above, all text surround by <brackets> are *tags* and additional information within tags are attributes (see \"type = 'section'\" in the div tag above).\n",
    "\n",
    "Since the goal of html is to display data, HTML is static with pre-defined tags.\n",
    "\n",
    "Meanwhile, the other popular markup language, XML - Extensible Markup Language - is designed to store and transfer data and thus allows the user to create their own tags. \n",
    "\n",
    "XML may be used to transfer data from one database to another. It may be used to store data. \n",
    "\n",
    "**Most importantly, for text analysis, xml can be used to encode text documents, tagging both structural elements (chapters, pages, sections, paragraphs, footnotes, etc.) and content (place and person names, dates, etc.). By encoding texts with xml, we can treat them like searchable databases. For example, if you have a corpus of medical journal articles, you may want to quickly search through the abstracts of each article and, if it fulfils a given search criteria, return the title, author, and date. Or you may choose to search through and extract the citations of each article only. Having these articles encoded with xml makes this easy.**\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9eac56cb",
   "metadata": {},
   "source": [
    "## xml as a data storage\n",
    "\n",
    "Sometimes, xml documents are created from scratch to record new information. Take for example, the document below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "654e27ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "### run this code to read in this document\n",
    "### note: the triple quotes (\"\"\") signify that the string continues across multiple lines until closed with a triple quote.\n",
    "patient_records = \"\"\"<?xml version='1.0' encoding='utf-8'?>\n",
    "<xml>\n",
    "    <head>\n",
    "        <title>Patient Records for Dr. Who</title>\n",
    "        <hospital>Mercy Hospital</title>\n",
    "        <doctor empID = \"2674AX\"><surname>Who</surname></doctor>\n",
    "    </head>\n",
    "    <body>\n",
    "        <patient>\n",
    "            <idnum>00866</idnum>\n",
    "            <name>\n",
    "                <prefix>Ms.</prefix>\n",
    "                <suffix/>\n",
    "                <surname>Washington</surname>\n",
    "                <firstname>María</firstname>\n",
    "            </name>\n",
    "            <gender genderCode = \"1\">female</gender>\n",
    "            <birthdate when=\"1964-05-22\">May 22, 1964</birthdate>\n",
    "            <birthplace>Little Rock, AR</birthplace>\n",
    "        </patient>\n",
    "\n",
    "        <patient>\n",
    "            <idnum>00982</idnum>\n",
    "            <name>\n",
    "                <prefix></prefix>\n",
    "                <suffix/>\n",
    "                <surname>Brown</surname>\n",
    "                <firstname>Nomi</firstname>\n",
    "            </name>\n",
    "            <gender genderCode = \"2\">non-binary / other</gender>\n",
    "            <birthdate when=\"1987-04-13\">April 13, 1987</birthdate>\n",
    "            <birthplace>Boston, MA</birthplace>\n",
    "        </patient>\n",
    "\n",
    "        <patient>\n",
    "            <idnum>00376</idnum>\n",
    "            <name>\n",
    "                <prefix>Dr.</prefix>\n",
    "                <suffix/>\n",
    "                <surname>Sánchez-Barillas</surname>\n",
    "                <firstname>Amos</firstname>\n",
    "            </name>\n",
    "            <gender genderCode = \"0\">male</gender>\n",
    "            <birthdate when=\"1999-12-31\">Dec 31, 1999</birthdate>\n",
    "            <birthplace>Nashua, NH</birthplace>\n",
    "        </patient>\n",
    "    </body>\n",
    "</xml>\n",
    "\"\"\""
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "015c6a2a",
   "metadata": {},
   "source": [
    "## I. Parsing xml from one xml document with BeautifulSoup\n",
    "\n",
    "We can parse the above xml document using **Beautiful Soup**, a Python library designed to extract data from HTML and XML files. We will use it to search for, export, and analyze data from some xml files. [Click here](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#xml) to view the documentation for BeautifulSoup.\n",
    "\n",
    "1. Let's import BeautifulSoup and all its subpackages:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ce353d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "from bs4 import *"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "046ec021",
   "metadata": {},
   "source": [
    "2. To parse our xml document of patient records above, we need to read it into BeautifulSoup and specify that we are parsing xml:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "2751f118",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<xml>\n",
      "<head>\n",
      "<title>Patient Records for Dr. Who</title>\n",
      "<hospital>Mercy Hospital</hospital>\n",
      "<doctor empID=\"2674AX\"><surname>Who</surname></doctor>\n",
      "</head>\n",
      "<body>\n",
      "<patient>\n",
      "<idnum>00866</idnum>\n",
      "<name>\n",
      "<prefix>Ms.</prefix>\n",
      "<suffix/>\n",
      "<surname>Washington</surname>\n",
      "<firstname>María</firstname>\n",
      "</name>\n",
      "<gender genderCode=\"1\">female</gender>\n",
      "<birthdate when=\"1964-05-22\">May 22, 1964</birthdate>\n",
      "<birthplace>Little Rock, AR</birthplace>\n",
      "</patient>\n",
      "<patient>\n",
      "<idnum>00982</idnum>\n",
      "<name>\n",
      "<prefix/>\n",
      "<suffix/>\n",
      "<surname>Brown</surname>\n",
      "<firstname>Nomi</firstname>\n",
      "</name>\n",
      "<gender genderCode=\"2\">non-binary / other</gender>\n",
      "<birthdate when=\"1987-04-13\">April 13, 1987</birthdate>\n",
      "<birthplace>Boston, MA</birthplace>\n",
      "</patient>\n",
      "<patient>\n",
      "<idnum>00376</idnum>\n",
      "<name>\n",
      "<prefix>Dr.</prefix>\n",
      "<suffix/>\n",
      "<surname>Sánchez-Barillas</surname>\n",
      "<firstname>Amos</firstname>\n",
      "</name>\n",
      "<gender genderCode=\"0\">male</gender>\n",
      "<birthdate when=\"1999-12-31\">Dec 31, 1999</birthdate>\n",
      "<birthplace>Nashua, NH</birthplace>\n",
      "</patient>\n",
      "</body>\n",
      "</xml>\n"
     ]
    }
   ],
   "source": [
    "soup = BeautifulSoup(patient_records, \"xml\")\n",
    "print(soup)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "573ff035",
   "metadata": {},
   "source": [
    "3. XML is a nested language, meaning each element or tag must be contained within a hierarchy of elements or tags. To better represent the nested nature of our xml document we can \"pretty print\" it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "839a28da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<?xml version=\"1.0\" encoding=\"utf-8\"?>\n",
      "<xml>\n",
      " <head>\n",
      "  <title>\n",
      "   Patient Records for Dr. Who\n",
      "  </title>\n",
      "  <hospital>\n",
      "   Mercy Hospital\n",
      "  </hospital>\n",
      "  <doctor empID=\"2674AX\">\n",
      "   Who\n",
      "  </doctor>\n",
      " </head>\n",
      " <body>\n",
      "  <patient>\n",
      "   <idnum>\n",
      "    00866\n",
      "   </idnum>\n",
      "   <name>\n",
      "    <prefix>\n",
      "     Ms.\n",
      "    </prefix>\n",
      "    <suffix/>\n",
      "    <surname>\n",
      "     Washington\n",
      "    </surname>\n",
      "    <firstname>\n",
      "     María\n",
      "    </firstname>\n",
      "   </name>\n",
      "   <gender genderCode=\"1\">\n",
      "    female\n",
      "   </gender>\n",
      "   <birthdate when=\"1964-05-22\">\n",
      "    May 22, 1964\n",
      "   </birthdate>\n",
      "   <birthplace>\n",
      "    Little Rock, AR\n",
      "   </birthplace>\n",
      "  </patient>\n",
      "  <patient>\n",
      "   <idnum>\n",
      "    00982\n",
      "   </idnum>\n",
      "   <name>\n",
      "    <prefix/>\n",
      "    <suffix/>\n",
      "    <surname>\n",
      "     Brown\n",
      "    </surname>\n",
      "    <firstname>\n",
      "     Naom\n",
      "    </firstname>\n",
      "   </name>\n",
      "   <gender genderCode=\"2\">\n",
      "    non-binary / other\n",
      "   </gender>\n",
      "   <birthdate when=\"1987-04-13\">\n",
      "    April 13, 1987\n",
      "   </birthdate>\n",
      "   <birthplace>\n",
      "    Boston, MA\n",
      "   </birthplace>\n",
      "  </patient>\n",
      "  <patient>\n",
      "   <idnum>\n",
      "    00376\n",
      "   </idnum>\n",
      "   <name>\n",
      "    <prefix>\n",
      "     Dr.\n",
      "    </prefix>\n",
      "    <suffix/>\n",
      "    <surname>\n",
      "     Sánchez-Barillas\n",
      "    </surname>\n",
      "    <firstname>\n",
      "     Amos\n",
      "    </firstname>\n",
      "   </name>\n",
      "   <gender genderCode=\"0\">\n",
      "    male\n",
      "   </gender>\n",
      "   <birthdate when=\"1999-12-31\">\n",
      "    Dec 31, 1999\n",
      "   </birthdate>\n",
      "   <birthplace>\n",
      "    Nashua, NH\n",
      "   </birthplace>\n",
      "  </patient>\n",
      " </body>\n",
      "</xml>\n"
     ]
    }
   ],
   "source": [
    "print(soup.prettify())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a0f8d9bc",
   "metadata": {},
   "source": [
    "4. We can quickly parse and pull out information from this text (now saved as \"soup\") using the following commands. Below, we will extract entire elements (tag + text) as well as just the text contained within a tag.\n",
    "\n",
    "Please see the [BeautifulSoup webpage](https://www.crummy.com/software/BeautifulSoup/bs4/doc/#xml) for more information and examples."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c7c6386a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<head>\n",
      "<title>Patient Records for Dr. Who</title>\n",
      "<hospital>Mercy Hospital</hospital>\n",
      "<doctor empID=\"2674AX\"><surname>Who</surname></doctor>\n",
      "</head>\n",
      "\n",
      "Patient Records for Dr. Who\n",
      "Mercy Hospital\n",
      "Who\n",
      "\n",
      "<title>Patient Records for Dr. Who</title>\n",
      "Patient Records for Dr. Who\n"
     ]
    }
   ],
   "source": [
    "print(soup.head)\n",
    "print(soup.head.text)\n",
    "print(soup.head.title)\n",
    "print(soup.head.title.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "556668bb",
   "metadata": {},
   "source": [
    "5. Let's see what happens when we ask for a tag that doesn't exist:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "3f6f3b45",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24724\\2953370273.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[1;32m----> 1\u001b[1;33m \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msoup\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mauthor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "print(soup.author.text)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "4bd5787d",
   "metadata": {},
   "source": [
    "5b. To avoid such errors interrupting our code, we can write an if statement such as:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "805157ac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "No author tag\n"
     ]
    }
   ],
   "source": [
    "author = soup.find(\"author\")\n",
    "if author: \n",
    "    print(author.text)\n",
    "else:\n",
    "    print(\"No author tag\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "ff2cd466",
   "metadata": {},
   "source": [
    "5c. We can also write a **try / except** statement to catch errors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "533ab0c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "there is no author listed\n"
     ]
    }
   ],
   "source": [
    "try:\n",
    "    author = soup.find(\"author\")\n",
    "    print(author.text)\n",
    "except AttributeError:\n",
    "    print(\"there is no author listed\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "8df8c397",
   "metadata": {},
   "source": [
    "6. If there are multiple instances of a tag, we can use **find_all** to retrieve all instances (**find** just retrieves the first instance)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "12b85be2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<surname>Who</surname>,\n",
       " <surname>Washington</surname>,\n",
       " <surname>Brown</surname>,\n",
       " <surname>Sánchez-Barillas</surname>]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "soup.find_all(\"surname\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "30b26f75",
   "metadata": {},
   "source": [
    "6b. In the case above, we may just want the surnames of patients and not the doctor. Since patient records are stored separately in the body tag we can simply:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "28654970",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[<surname>Washington</surname>,\n",
       " <surname>Brown</surname>,\n",
       " <surname>Sánchez-Barillas</surname>]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "body = soup.body\n",
    "body.find_all(\"surname\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "0e8e5d4c",
   "metadata": {},
   "source": [
    "7. We can then iterate through each patient and retrieve information about each."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "08b66037",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3\n"
     ]
    }
   ],
   "source": [
    "patients = body.find_all(\"patient\")\n",
    "print(len(patients))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "8ef561cd",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'text'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[1;32m~\\AppData\\Local\\Temp\\ipykernel_24724\\740894057.py\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      5\u001b[0m     \u001b[0mpat_first\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpatient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfirstname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m     \u001b[0mpat_last\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpatient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msurname\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 7\u001b[1;33m     \u001b[0mpat_prefix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpatient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mprefix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      8\u001b[0m     \u001b[0mpat_suffix\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpatient\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msuffix\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtext\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m     \u001b[0mpat_fullname\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mpat_prefix\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpat_first\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpat_last\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mpat_suffix\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mAttributeError\u001b[0m: 'NoneType' object has no attribute 'text'"
     ]
    }
   ],
   "source": [
    "patient_list = []\n",
    "\n",
    "for patient in patients:\n",
    "    pat_id = patient.idnum.text\n",
    "    pat_first = patient.firstname.text\n",
    "    pat_last = patient.surname.text\n",
    "    pat_prefix = patient.prefix.text\n",
    "    pat_suffix = patient.suffix.text\n",
    "    pat_fullname = pat_prefix + pat_first + pat_last + pat_suffix\n",
    "    pat_birthyear = patient.birthdate['when'].text[:4]\n",
    "    pat_birthstate = patient.birthplace.text[-2:]\n",
    "    patient_list.append(pat_id, pat_fullname, pat_birthyear, pat_birthstate)    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e7fa9050",
   "metadata": {},
   "source": [
    "8. You may notice an **AttributeError** above. This occurs when one of the tags, attributes, or other items we are looking for do not exist. One way to avoid this is to wrap each instruction in **try / except** statements. For example:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "582b91c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "patient_list = []\n",
    "\n",
    "for patient in patients:\n",
    "    try:\n",
    "        pat_id = patient.idnum.text\n",
    "    except AttributeError:\n",
    "        pat_id = \"\"\n",
    "    try:\n",
    "        pat_first = patient.firstname.text\n",
    "        pat_last = patient.surname.text\n",
    "    except AttributeError:\n",
    "        print(\"missing required info: names\")\n",
    "        continue\n",
    "    try:\n",
    "        pat_prefix = patient.prefix.text\n",
    "    except AttributeError:\n",
    "        pat_prefix = \"\"\n",
    "    try:\n",
    "        pat_suffix = patient.suffix.text\n",
    "    except AttributeError:\n",
    "        pat_suffix = \"\"\n",
    "    pat_fullname = ' '.join([pat_prefix, pat_first, pat_last, pat_suffix])\n",
    "    try:\n",
    "        pat_birthyear = patient.birthdate['when'][:4]\n",
    "    except AttributeError:\n",
    "        pat_birthyear = \"\"\n",
    "    try:\n",
    "        pat_birthstate = patient.birthplace.text[-2:]\n",
    "    except AttributeError:\n",
    "        pat_birthstate = \"\"\n",
    "    patient_list.append([pat_id, pat_fullname, pat_birthyear, pat_birthstate])      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "61b79da2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['00866', ' María Washington ', '1964', 'AR'], ['00982', ' Nomi Brown ', '1987', 'MA'], ['00376', ' Amos Sánchez-Barillas ', '1999', 'NH']]\n"
     ]
    }
   ],
   "source": [
    "print(patient_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d4a7d933",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>idnum</th>\n",
       "      <th>full_name</th>\n",
       "      <th>birth_year</th>\n",
       "      <th>birth_state</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>00866</td>\n",
       "      <td>María Washington</td>\n",
       "      <td>1964</td>\n",
       "      <td>AR</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>00982</td>\n",
       "      <td>Nomi Brown</td>\n",
       "      <td>1987</td>\n",
       "      <td>MA</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>00376</td>\n",
       "      <td>Amos Sánchez-Barillas</td>\n",
       "      <td>1999</td>\n",
       "      <td>NH</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   idnum                full_name birth_year birth_state\n",
       "0  00866        María Washington        1964          AR\n",
       "1  00982              Nomi Brown        1987          MA\n",
       "2  00376   Amos Sánchez-Barillas        1999          NH"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "patient_df = pd.DataFrame(patient_list, columns = [\"idnum\", \"full_name\", \"birth_year\", \"birth_state\"])\n",
    "patient_df.head()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "69a571fb",
   "metadata": {},
   "source": [
    "<h2>Exercise for Part I</h2>\n",
    "\n",
    "9. Create a dataframe for our patients just like we did above. But, this time, include columns for the patients birth month and initials."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cfe21f4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1d64b5e3",
   "metadata": {},
   "source": [
    "## Part II: Parsing xml across a corpus of texts"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "51164a99",
   "metadata": {},
   "source": [
    "10. Let's open a small corpus of xml documents:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "6769f09d",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "from pathlib import Path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "c636a77c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "C:\\Users\\F0040RP\\shared\\RR-workshop-data\\lts_xml\n"
     ]
    }
   ],
   "source": [
    "#Path(\"~/shared/RR-workshop-data/lts_xml\").expanduser().exists()\n",
    "xmldir = Path(\"~/shared/RR-workshop-data/lts_xml\").expanduser()\n",
    "\n",
    "print(xmldir)\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2dc41785",
   "metadata": {},
   "source": [
    "11. Using the directory above, we are going to import xml documents created from Holocaust survivor testimony stored on the website [Let Them Speak](https://dhlab.yale.edu/projects/let-them-speak/), which was drawn from testimony recorded by the United States Holocaust Memorial Museum and the Shoah Foundation.\n",
    "\n",
    "**The subject matter in this dataset is heavy stuff. But, since I worked with a Holocaust Studies group recently, it is what I have readily available in xml (my other option was my corpus of documents from colonial Peru, also heavy subject matter and in Spanish). Anyways, wee will not be reading these texts, but instead just pulling out some information from them.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "0e3757c7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['RG-50.030-0015.xml', 'RG-50.030-0060.xml', 'RG-50.030-0072.xml', 'RG-50.030-0082.xml', 'RG-50.030-0083.xml', 'RG-50.030-0145.xml', 'RG-50.030-0198.xml', 'RG-50.030-0210.xml', 'RG-50.030-0234.xml', 'RG-50.030-0315.xml', 'RG-50.030-0316.xml', 'RG-50.030-0546.xml', 'RG-50.031-0075.xml', 'RG-50.106-0118.xml', 'RG-50.106-0139.xml', 'RG-50.165-0016.xml', 'RG-50.165-0123.xml', 'RG-50.233-0036.xml', 'RG-50.322-0005.xml', 'RG-50.462-0081.xml', 'RG-50.462-0102.xml', 'RG-50.470-0008.xml', 'RG-50.471-0013.xml', 'RG-50.471-0013b.xml', 'RG-50.549.02-0054.xml', 'RG-50.562-0005.xml']\n"
     ]
    }
   ],
   "source": [
    "pathlist = sorted(xmldir.glob(\"*.xml\")) \n",
    "print([path.name for path in pathlist])"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "99f07fd8",
   "metadata": {},
   "source": [
    "12. Let's just see what one of these texts looks like, by examining what tags are found in it.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "3ddcb3ee",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'xml', 'front', 'question', 'answer', 'p', 'body', 'text', 'back'}\n"
     ]
    }
   ],
   "source": [
    "with open(pathlist[0], encoding = 'utf-8') as f:\n",
    "    example_doc = f.read()\n",
    "ex_soup = soup\n",
    "children_list = []\n",
    "for child in soup.recursiveChildGenerator():\n",
    "    if child.name:\n",
    "        children_list.append(child.name)\n",
    "\n",
    "print(set(children_list))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "08a0db9a",
   "metadata": {},
   "source": [
    "12b. We can also quickly print out the front tag info from this text:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "43f0ad8c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<front>\n",
      "<p>Cite as: \"Oral history interview with Mark Moskovitz, USHMM\" in: Gabor M. Toth, In Search of the Drowned: Testimonies and Testimonial Fragments of the Holocaust (Yale Fortunoff Archive, 2021), lts.fortunoff.library.yale.edu.</p>\n",
      "<p>Shelfmark: USHMM RG-50.562*0005</p>\n",
      "<p>Provenance: The United States Holocaust Memorial Museum Oral History Branch conducted the interview with Mark Moskovitz on October 4, 2004. The interview was conducted as part of the United States Holocaust Memorial Museum Oral History Project with David Boder Interviewees as a follow up to Boder's 1946 interviews. The interview was received by the United States Holocaust Memorial Museum Archives Branch in October 2004.</p>\n",
      "<p>Interview Summary</p>\n",
      "<p>Mark Moskovitz discusses his experiences during the Holocaust and his life since 1946 when he was interviewed as a displaced person by American psychology professor, David P. Boder</p>\n",
      "<p>Oral history interview with Mark Moskovitz</p>\n",
      "<p/>\n",
      "<p>United States Holocaust Memorial Museum Interview with Mark Moskovitz</p>\n",
      "<p/>\n",
      "<p>October 4, 2004</p>\n",
      "<p/>\n",
      "<p>RG-50.562*0005</p>\n",
      "<p/>\n",
      "<p>PREFACE The following oral history testimony is the result of a videotaped interview with Mark Moskovitz, conducted by Neenah Ellis on October 4, 2004, on behalf of the United States Holocaust Memorial Museum. The interview took place in Van Nuys, California, and is part of the United States Holocaust Memorial Museum's collection of oral testimonies. Rights to the interview are held by the United States Holocaust Memorial Museum.</p>\n",
      "<p/>\n",
      "<p>The reader should bear in mind that this is a verbatim transcript of spoken, rather than written prose. This transcript has been neither checked for spelling nor verified for accuracy, and therefore, it is possible that there are errors. As a result, nothing should be quoted or used from this transcript without first checking it against the taped interview.</p>\n",
      "<p/>\n",
      "<p>Interview with Mark Moskovitz</p>\n",
      "<p/>\n",
      "<p>October 4, 2004</p>\n",
      "<p/>\n",
      "<p>Beginning Tape One</p>\n",
      "<p/>\n",
      "</front>\n"
     ]
    }
   ],
   "source": [
    "print(ex_soup.front)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "edc2c504",
   "metadata": {},
   "source": [
    "13. As you notice, this text includes \"question\" and \"answer\" tags to reflect this testimony was acquired through an interview. \n",
    "\n",
    "I wondered, when first perusing these testimonies, what I could learn from just reviewing the questions asked. In particular, I wanted to know: did the interviewers have a set of questions planned ahead of time, or did they improvise follow-up questions based on what the interviewees told them? (or was it somewhere in between?)\n",
    "\n",
    "To get a quick overview of these texts without getting into the serious nature of the content, let's create a list and fill it with all questions asked across these 26 testimonies (setting answers aside for now)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4806870f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The document 'RG-50.030-0015' has 25 questions.\n",
      "The document 'RG-50.030-0060' has 13 questions.\n",
      "The document 'RG-50.030-0072' has 25 questions.\n",
      "The document 'RG-50.030-0082' has 176 questions.\n",
      "The document 'RG-50.030-0083' has 24 questions.\n",
      "The document 'RG-50.030-0145' has 17 questions.\n",
      "The document 'RG-50.030-0198' has 10 questions.\n",
      "The document 'RG-50.030-0210' has 40 questions.\n",
      "The document 'RG-50.030-0234' has 132 questions.\n",
      "The document 'RG-50.030-0315' has NO questions.\n",
      "The document 'RG-50.030-0316' has NO questions.\n",
      "The document 'RG-50.030-0546' has 162 questions.\n",
      "The document 'RG-50.031-0075' has NO questions.\n",
      "The document 'RG-50.106-0118' has 185 questions.\n",
      "The document 'RG-50.106-0139' has 207 questions.\n",
      "The document 'RG-50.165-0016' has NO questions.\n",
      "The document 'RG-50.165-0123' has NO questions.\n",
      "The document 'RG-50.233-0036' has 275 questions.\n",
      "The document 'RG-50.322-0005' has 253 questions.\n",
      "The document 'RG-50.462-0081' has NO questions.\n",
      "The document 'RG-50.462-0102' has NO questions.\n",
      "The document 'RG-50.470-0008' has NO questions.\n",
      "The document 'RG-50.471-0013' has 190 questions.\n",
      "The document 'RG-50.471-0013b' has 190 questions.\n",
      "The document 'RG-50.549.02-0054' has 71 questions.\n",
      "The document 'RG-50.562-0005' has 608 questions.\n"
     ]
    }
   ],
   "source": [
    "Qlist = []\n",
    "\n",
    "for path in pathlist:\n",
    "    with open(path) as f:\n",
    "        xmldoc = f.read()\n",
    "    soup = BeautifulSoup(xmldoc, \"xml\")\n",
    "    body = soup.body\n",
    "    questions = body.find_all(\"question\")\n",
    "    if len(questions) > 0:\n",
    "        print(f\"The document '{path.stem}' has {len(questions)} questions.\")\n",
    "    else: \n",
    "        print(f\"The document '{path.stem}' has NO questions.\")\n",
    "    Qlist.extend([question.text for question in questions])\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fcb6a732",
   "metadata": {},
   "source": [
    "14. Now, let's peruse some of the questions found in this text."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "b697274c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2603\n",
      "['Please tell us your name, where you were born, and when you were born?', 'Tell us about your family and your childhood before the war.', 'At the border?', 'Tell us what happened to you and your mother after your brother was taken.', 'Who...who came to your mother?', 'What was life like daily in the convent?', 'And what did you do during the day?', 'How did you get along with the other children?', 'Did you see your mother often? How did you get from the convent to the Protestant community.', 'Tonsils?', 'Had you had no contact with your father at this point?', 'What happened after the liberation?', 'You said your husband was in high school with you.', \"No. That's what I wondered.\", 'Okay.', 'Yes. Tell me about the...the early years after the war.', 'Have you...uh...made contact with your family.', 'Do you have family here?', 'All right. Thank you. Was it so hard as you thought?', 'And that was the first you knew that?']\n",
      "...\n",
      "['Do you remember his last name?', 'Related?', 'What’s his last name?', 'Your cousin?', 'And this was the last time this whole group was together?', 'Sure, I know.', 'Okay, go ahead.', 'That’s when you found out that he was still --', 'When did he leave there? When did he leave --', 'It’s a long time.', 'Okay.', 'So you think this is ’46?', 'And -- and that’s your cousin there on the left?', 'Yeah.', 'Good. And there -- is there one more?', 'That’s it.', 'And who’s the lady?', 'You’d just been married recently?', 'Good. Okay.', 'So they will use it later for editing.']\n"
     ]
    }
   ],
   "source": [
    "print(len(Qlist))\n",
    "print(Qlist[:20])\n",
    "print(\"...\")\n",
    "print(Qlist[-20:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "id": "6fdbdfe2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['After the war, you mean?',\n",
       " 'How long did you stay there, do you remember? Not very long?',\n",
       " '-- that you came across to France from Italy, you walked. But before you tell me the rest of the story, I would like to go back and ask you a few questions about your --',\n",
       " 'Where did you come to?',\n",
       " \"Abe, can you go back for just a minute because it wasn't clear. You were in Flossenberg, in the subcamp of Flossenberg. When were you taken to Therenienstadt.\",\n",
       " 'You saw that?',\n",
       " 'OK! When you were in the University, there were so many leading philosophers who were anti-Semitic in terms of their writings.',\n",
       " '-- you think, when you went into the ghetto --',\n",
       " 'The tears of the mothers?',\n",
       " 'Right.',\n",
       " 'Right.',\n",
       " 'Tell me more about it, tell me more about that.',\n",
       " 'Som-Somebody just walked in, let’s take a break. [tape break] Okay, we are back.',\n",
       " 'Did you want -- had -- did you want children?',\n",
       " 'Wait, take your glasses off and you have to sit back. Now tell me about that picture.',\n",
       " 'Was there panic?',\n",
       " 'Okay, do you remember when Sylvia was born, what year she was born in?',\n",
       " 'What did he tell you.',\n",
       " 'They were beating people up?',\n",
       " 'Do you remember when the war started.']"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we can also extract 20 randomly selected questions from this list\n",
    "import random\n",
    "random.choices(Qlist, k = 20)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "2d4a9018",
   "metadata": {},
   "source": [
    "As you can see, these questions to do not appear to be planned in advance. There also appear to be some answers and statements that appear to have been erroneously tagged as questions."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "vscode": {
   "interpreter": {
    "hash": "92ccb6e3f8e1ba46ac70611fe300a00d231540f34c9f821035b67580ebdf166e"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
